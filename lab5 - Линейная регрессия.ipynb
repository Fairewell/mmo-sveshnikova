{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание задачи и загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой работе будем работать с одним из классических наборов данных в статистике, содержащим информацию о бриллиантах и решать задачу предсказания цены бриллианта price в зависимости от его характеристик.. Описание можно посмотреть здесь (https://www.kaggle.com/datasets/shivam2503/diamonds). Загрузите датасет `diamonds.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/diamonds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли в наборе данных пропущенные значения? Если да, удалите их. Также выведите на экран число пропусков в каждом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "carat         0\n",
      "cut           0\n",
      "color         0\n",
      "clarity       0\n",
      "depth         0\n",
      "table         0\n",
      "price         0\n",
      "x             0\n",
      "y             0\n",
      "z             0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows after removing: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "print(f\"\\nNumber of duplicate rows after removing: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли в наборе данных бессмысленные столбцы (признаки, не несущие дополнительной информации)? Если да, то удалите их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "# !             ^^^-------------------Дублирует индексы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия основана на предположении о линейной связи между признаками и целевой переменной, а потому перед выбором переменных для включения в модель имеет смысл проверить, насколько эта связь выполняется. Выясним корреляцию между признаками.\n",
    "Выведите матрицу корреляций между всеми вещественными признаками и целевой переменной.\n",
    "Какой вещественный признак коррелирует с целевой переменной больше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       carat  cut  color  clarity  depth  table  price     x     y     z\n",
      "0       0.23    4      5        1   61.5   55.0    326  3.95  3.98  2.43\n",
      "1       0.21    3      5        2   59.8   61.0    326  3.89  3.84  2.31\n",
      "2       0.23    1      5        4   56.9   65.0    327  4.05  4.07  2.31\n",
      "3       0.29    3      1        3   62.4   58.0    334  4.20  4.23  2.63\n",
      "4       0.31    1      0        1   63.3   58.0    335  4.34  4.35  2.75\n",
      "...      ...  ...    ...      ...    ...    ...    ...   ...   ...   ...\n",
      "53935   0.72    4      6        2   60.8   57.0   2757  5.75  5.76  3.50\n",
      "53936   0.72    1      6        2   63.1   55.0   2757  5.69  5.75  3.61\n",
      "53937   0.70    2      6        2   62.8   60.0   2757  5.66  5.68  3.56\n",
      "53938   0.86    3      2        1   61.0   58.0   2757  6.15  6.12  3.74\n",
      "53939   0.75    4      6        1   62.2   55.0   2757  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlad9\\AppData\\Local\\Temp\\ipykernel_9996\\3483754725.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[column] = df[column].replace(mapping)\n"
     ]
    }
   ],
   "source": [
    "# Словарь для замены значений\n",
    "replace_temp = {\n",
    "    'cut': {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4},\n",
    "    'color': {'D': 6, 'E': 5, 'F': 4, 'G': 3, 'H': 2, 'I': 1, 'J': 0},\n",
    "    'clarity': {'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7}\n",
    "}\n",
    "\n",
    "# Замена значений непосредственно в df\n",
    "for column, mapping in replace_temp.items():\n",
    "    df[column] = df[column].replace(mapping)\n",
    "\n",
    "# Проверка результата\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            carat       cut     color   clarity     depth     table     price  \\\n",
      "carat    1.000000 -0.134967 -0.291437 -0.352841  0.028224  0.181618  0.921591   \n",
      "cut     -0.134967  1.000000  0.020519  0.189175 -0.218055 -0.433405 -0.053491   \n",
      "color   -0.291437  0.020519  1.000000 -0.025631 -0.047279 -0.026465 -0.172511   \n",
      "clarity -0.352841  0.189175 -0.025631  1.000000 -0.067384 -0.160327 -0.146800   \n",
      "depth    0.028224 -0.218055 -0.047279 -0.067384  1.000000 -0.295779 -0.010647   \n",
      "table    0.181618 -0.433405 -0.026465 -0.160327 -0.295779  1.000000  0.127134   \n",
      "price    0.921591 -0.053491 -0.172511 -0.146800 -0.010647  0.127134  1.000000   \n",
      "x        0.975094 -0.125565 -0.270287 -0.371999 -0.025289  0.195344  0.884435   \n",
      "y        0.951722 -0.121462 -0.263584 -0.358420 -0.029341  0.183760  0.865421   \n",
      "z        0.953387 -0.149323 -0.268227 -0.366952  0.094924  0.150929  0.861249   \n",
      "\n",
      "                x         y         z  \n",
      "carat    0.975094  0.951722  0.953387  \n",
      "cut     -0.125565 -0.121462 -0.149323  \n",
      "color   -0.270287 -0.263584 -0.268227  \n",
      "clarity -0.371999 -0.358420 -0.366952  \n",
      "depth   -0.025289 -0.029341  0.094924  \n",
      "table    0.195344  0.183760  0.150929  \n",
      "price    0.884435  0.865421  0.861249  \n",
      "x        1.000000  0.974701  0.970772  \n",
      "y        0.974701  1.000000  0.952006  \n",
      "z        0.970772  0.952006  1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Наиболее коррелирующий признак с price:\n",
      " carat    0.921591\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Выяснение признака с наибольшей корреляцией с price\n",
    "correlation_with_price = correlation_matrix['price'].sort_values(ascending=False)\n",
    "print(\"\\nНаиболее коррелирующий признак с price:\\n\", correlation_with_price[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наиболее коррелирующий с price признак — это `carat` (коэффициент корреляции **0.92**). Это говорит о том, что вес бриллианта (карат) наиболее тесно связан с его ценой, что логично, поскольку больший вес, как правило, увеличивает стоимость бриллианта.\n",
    "- Другие числовые признаки, такие как `x`, `y`, и `z` (размеры бриллианта), также показывают высокую корреляцию с price (в пределах **0.86**–**0.88**), так как они связаны с размером и массой бриллианта.\n",
    "- Признаки `cut`, `color`, и `clarity` показывают меньшую корреляцию с `price`. В отличие от веса и размеров, они имеют косвенное влияние на цену, возможно, из-за их дискретного характера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как линейная модель складывает значения признаков с некоторыми весами, нам нужно аккуратно обработать категориальные признаки. Закодируйте категориальные переменные при помощи OneHot-кодирования (pd.get_dummies). Не забудьте поставить значение параметра drop_first равным True.\n",
    "\n",
    "P.S. Числовые столбцы оставляем в таблице без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot-кодирование категориальных признаков\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       carat  cut  color  clarity  depth  table  price     x     y     z\n",
      "0       0.23    4      5        1   61.5   55.0    326  3.95  3.98  2.43\n",
      "1       0.21    3      5        2   59.8   61.0    326  3.89  3.84  2.31\n",
      "2       0.23    1      5        4   56.9   65.0    327  4.05  4.07  2.31\n",
      "3       0.29    3      1        3   62.4   58.0    334  4.20  4.23  2.63\n",
      "4       0.31    1      0        1   63.3   58.0    335  4.34  4.35  2.75\n",
      "...      ...  ...    ...      ...    ...    ...    ...   ...   ...   ...\n",
      "53935   0.72    4      6        2   60.8   57.0   2757  5.75  5.76  3.50\n",
      "53936   0.72    1      6        2   63.1   55.0   2757  5.69  5.75  3.61\n",
      "53937   0.70    2      6        2   62.8   60.0   2757  5.66  5.68  3.56\n",
      "53938   0.86    3      2        1   61.0   58.0   2757  6.15  6.12  3.74\n",
      "53939   0.75    4      6        1   62.2   55.0   2757  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте матрицу X, содержащую все признаки, и не содержащую целевую переменную price. Также создайте вектор y, содержащий целевую переменную price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица X:\n",
      "       carat  cut  color  clarity  depth  table     x     y     z\n",
      "0       0.23    4      5        1   61.5   55.0  3.95  3.98  2.43\n",
      "1       0.21    3      5        2   59.8   61.0  3.89  3.84  2.31\n",
      "2       0.23    1      5        4   56.9   65.0  4.05  4.07  2.31\n",
      "3       0.29    3      1        3   62.4   58.0  4.20  4.23  2.63\n",
      "4       0.31    1      0        1   63.3   58.0  4.34  4.35  2.75\n",
      "...      ...  ...    ...      ...    ...    ...   ...   ...   ...\n",
      "53935   0.72    4      6        2   60.8   57.0  5.75  5.76  3.50\n",
      "53936   0.72    1      6        2   63.1   55.0  5.69  5.75  3.61\n",
      "53937   0.70    2      6        2   62.8   60.0  5.66  5.68  3.56\n",
      "53938   0.86    3      2        1   61.0   58.0  6.15  6.12  3.74\n",
      "53939   0.75    4      6        1   62.2   55.0  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 9 columns]\n",
      "\n",
      "Вектор y:\n",
      "0         326\n",
      "1         326\n",
      "2         327\n",
      "3         334\n",
      "4         335\n",
      "         ... \n",
      "53935    2757\n",
      "53936    2757\n",
      "53937    2757\n",
      "53938    2757\n",
      "53939    2757\n",
      "Name: price, Length: 53940, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Создание матрицы X, содержащей все признаки, кроме целевой переменной price\n",
    "X = df.drop(columns=['price'])\n",
    "\n",
    "# Создание вектора y, содержащего целевую переменную price\n",
    "y = df['price']\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Матрица X:\")\n",
    "print(X)\n",
    "print(\"\\nВектор y:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку на тренировочную и тестовую. Долю тестовой выборки укажите равной 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабируйте вещественные признаки тренировочной и тестовой выборок при помощи модуля StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите на экран веса, которые линейная регрессия присвоила признакам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Веса признаков:\n",
      " [10697.32682679   120.5213228    324.12780762   504.09390002\n",
      "   -78.64608396   -27.50801659  -842.42154479    25.3297773\n",
      "   -23.67989821]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод весов\n",
    "weights = model.coef_\n",
    "print(\"Веса признаков:\\n\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Самые значимые положительные веса при обучении линейной регрессии получила переменная `carat`, что подтверждает выводы корреляционного анализа. Она оказывает наибольшее влияние на итоговую стоимость.\n",
    "- Категориальные признаки (`cut`, `color`, и `clarity`) получили меньшие веса, что указывает на их менее выраженное влияние на цену в сравнении с весом (`carat`) и размерами (`x`, `y`, `z`).\n",
    "- Признак `depth` получил отрицательное значение, что может указывать на негативное влияние на цену при увеличении значения глубины. Показатель глубины, вероятно, влияет на оптические характеристики и может быть менее важным фактором, чем другие параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцените качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели:\n",
      "R^2: 0.9075\n",
      "MAE: 802.20\n",
      "RMSE: 1201.21\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Качество модели:\\nR^2: {r2:.4f}\\nMAE: {mae:.2f}\\nRMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент детерминации \n",
    "$𝑅^2=0.9075$ говорит о том, что модель объясняет около **90.75%** вариации цены бриллиантов. Это достаточно высокий показатель для линейной модели, что говорит о хорошей пригодности признаков для предсказания цены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попытка улучшить качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить из анализа корреляционной матрицы, между некоторыми признаками имеется сильная корреляция, что может быть индикатором проблемы мультиколлинеарности. Для решения этой проблемы можно либо исключить некоторые признаки из модели (например, если признак линейно зависим с какими-то другими, его можно исключить из модели, т.е. удалить из матрицы объект-признак и заново обучить модель).\n",
    "\n",
    "Удалите из матриц Xtrain и Xtest признак, который наиболее сильно коррелирует с остальными. Заново обучите модель и оцените её качество. Улучшилось ли качество модели?\n",
    "\n",
    "Попробуйте удалить какой-то другой признак (можете попробовать несколько вариантов). Помогло ли это улучшить качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vlad9\\Documents\\study\\4 kurs\\1 semestr\\mmo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vlad9\\Documents\\study\\4 kurs\\1 semestr\\mmo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with 'x' dropped: R^2 = 0.9064396809771065 MAE = 820.8829146645131 RMSE = 1207.9583217743657\n",
      "Results with 'y' dropped: R^2 = 0.9074680832173811 MAE = 802.1746080128538 RMSE = 1201.3011210718282\n",
      "Results with 'z' dropped: R^2 = 0.9074812143411896 MAE = 802.22214336385 RMSE = 1201.2158802491251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vlad9\\Documents\\study\\4 kurs\\1 semestr\\mmo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# копируем\n",
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()\n",
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    return r2, mae, rmse\n",
    "\n",
    "# Удаляем признак 'x' и обучаем модель\n",
    "X_train_x_dropped = X_train_copy.drop(columns=['x'])\n",
    "X_test_x_dropped = X_test_copy.drop(columns=['x'])\n",
    "r2_x, mae_x, rmse_x = evaluate_model(X_train_x_dropped, X_test_x_dropped, y_train, y_test)\n",
    "\n",
    "# Удаляем признак 'y' и обучаем модель\n",
    "X_train_y_dropped = X_train_copy.drop(columns=['y'])\n",
    "X_test_y_dropped = X_test_copy.drop(columns=['y'])\n",
    "r2_y, mae_y, rmse_y = evaluate_model(X_train_y_dropped, X_test_y_dropped, y_train, y_test)\n",
    "\n",
    "# Удаляем признак 'z' и обучаем модель\n",
    "X_train_z_dropped = X_train_copy.drop(columns=['z'])\n",
    "X_test_z_dropped = X_test_copy.drop(columns=['z'])\n",
    "r2_z, mae_z, rmse_z = evaluate_model(X_train_z_dropped, X_test_z_dropped, y_train, y_test)\n",
    "\n",
    "# Результаты\n",
    "print(\"Results with 'x' dropped: R^2 =\", r2_x, \"MAE =\", mae_x, \"RMSE =\", rmse_x)\n",
    "print(\"Results with 'y' dropped: R^2 =\", r2_y, \"MAE =\", mae_y, \"RMSE =\", rmse_y)\n",
    "print(\"Results with 'z' dropped: R^2 =\", r2_z, \"MAE =\", mae_z, \"RMSE =\", rmse_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда генерация новых признаков помогает модели лучше находить взаимосвязи между целевой переменной и признаками. Попробуйте придумать новые признаки и добавить их в модель.\n",
    "\n",
    "Помогло ли это улучшить качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with new features: R^2 = 0.9073839332975575 MAE = 793.9933766393364 RMSE = 1201.8472376115399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlad9\\AppData\\Local\\Temp\\ipykernel_9996\\609159599.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_copy['xy_ratio'].fillna(X_train_copy['xy_ratio'].mean(), inplace=True)\n",
      "C:\\Users\\vlad9\\AppData\\Local\\Temp\\ipykernel_9996\\609159599.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_copy['xy_ratio'].fillna(X_test_copy['xy_ratio'].mean(), inplace=True)\n",
      "C:\\Users\\vlad9\\AppData\\Local\\Temp\\ipykernel_9996\\609159599.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_copy['depth_table_ratio'].fillna(X_train_copy['depth_table_ratio'].mean(), inplace=True)\n",
      "C:\\Users\\vlad9\\AppData\\Local\\Temp\\ipykernel_9996\\609159599.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_copy['depth_table_ratio'].fillna(X_test_copy['depth_table_ratio'].mean(), inplace=True)\n",
      "c:\\Users\\vlad9\\Documents\\study\\4 kurs\\1 semestr\\mmo\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Обработка NaN значений в новых признаках\n",
    "X_train_copy['xy_ratio'].fillna(X_train_copy['xy_ratio'].mean(), inplace=True)\n",
    "X_test_copy['xy_ratio'].fillna(X_test_copy['xy_ratio'].mean(), inplace=True)\n",
    "\n",
    "X_train_copy['depth_table_ratio'].fillna(X_train_copy['depth_table_ratio'].mean(), inplace=True)\n",
    "X_test_copy['depth_table_ratio'].fillna(X_test_copy['depth_table_ratio'].mean(), inplace=True)\n",
    "\n",
    "# Проверка и обучение модели\n",
    "r2_new, mae_new, rmse_new = evaluate_model(X_train_copy, X_test_copy, y_train, y_test)\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Results with new features: R^2 =\", r2_new, \"MAE =\", mae_new, \"RMSE =\", rmse_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте улучшить модель, используя кросс-валидацию и регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший alpha для Ridge: 61.35907273413169\n",
      "Лучший alpha для Lasso: 6.13590727341317\n",
      "Оценка Ridge модели: 0.9072794712275332\n",
      "Оценка Lasso модели: 0.9071261947331591\n"
     ]
    }
   ],
   "source": [
    "# ! 1. Подбор оптимального alpha для Ridge\n",
    "ridge_alphas = np.logspace(-2, 3, 100)  # диапазон значений alpha для Ridge\n",
    "ridge_scores = []\n",
    "\n",
    "for alpha in ridge_alphas:\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    score = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    ridge_scores.append(score)\n",
    "\n",
    "best_alpha_ridge = ridge_alphas[np.argmax(ridge_scores)]\n",
    "print(\"Лучший alpha для Ridge:\", best_alpha_ridge)\n",
    "\n",
    "# 2. Подбор оптимального alpha для Lasso, начиная с найденного alpha для Ridge\n",
    "lasso_alphas = np.linspace(0.1 * best_alpha_ridge, 2 * best_alpha_ridge, 50)  # диапазон alpha на основе Ridge\n",
    "lasso_scores = []\n",
    "\n",
    "for alpha in lasso_alphas:\n",
    "    lasso_model = Lasso(alpha=alpha, max_iter=10000)  # увеличим max_iter для лучшей сходимости\n",
    "    score = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring='r2').mean()\n",
    "    lasso_scores.append(score)\n",
    "\n",
    "best_alpha_lasso = lasso_alphas[np.argmax(lasso_scores)]\n",
    "print(\"Лучший alpha для Lasso:\", best_alpha_lasso)\n",
    "\n",
    "# Оценка моделей с наилучшими значениями alpha\n",
    "ridge_model_final = Ridge(alpha=best_alpha_ridge).fit(X_train_scaled, y_train)\n",
    "lasso_model_final = Lasso(alpha=best_alpha_lasso, max_iter=10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_score_final = ridge_model_final.score(X_test_scaled, y_test)\n",
    "lasso_score_final = lasso_model_final.score(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Оценка Ridge модели:\", ridge_score_final)\n",
    "print(\"Оценка Lasso модели:\", lasso_score_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Удаление коррелирующих признаков** немного улучшило `MAE`, особенно после удаления признака `y`. Однако общая метрика $R^2$ осталась практически без изменений. Это свидетельствует о том, что мультиколлинеарность не сильно мешала модели.\n",
    "\n",
    "2. **Добавление новых признаков** слегка улучшило метрику `MAE`, но практически не повлияло на $R^2$ и `RMSE`. Видимо, добавленные признаки имеют небольшое значение для модели.\n",
    "\n",
    "3. **Кросс-валидация и регуляризация** (*Ridge* и *Lasso*): Использование кросс-валидации и регуляризации с подбором `alpha` также не привело к значительным улучшениям. *Ridge* показала немного лучшую оценку $R^2$, но разница минимальна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации\n",
    "- **Комбинированная регуляризация** (`Elastic Net`): Можно попробовать `Elastic Net`, чтобы объединить преимущества `L1` и `L2` регуляризации. Он может учесть взаимосвязи и контролировать мультиколлинеарность.\n",
    "\n",
    "- **Нелинейные модели**: Возможно, стоит попробовать нелинейные модели (например, `Random Forest` или `Gradient Boosting`), если линейные методы исчерпали себя."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
